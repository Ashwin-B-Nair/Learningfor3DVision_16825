{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16-825 Learning for 3D Vision\n",
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Rendering your first mesh\n",
    "\n",
    "![SegmentLocal](results/textured_cow.jpg \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Practicing with Cameras\n",
    "\n",
    "### 1.1. 360-degree Renders\n",
    "\n",
    "![SegmentLocal](results/360_cow.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Re-creating the Dolly Zoom\n",
    "\n",
    "![SegmentLocal](results/dolly_zoom.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Practicing with Meshes\n",
    "### 2.1 Constructing a Tetrahedron\n",
    "\n",
    "![SegmentLocal](results/360_tetrahedron.gif \"segment\")\n",
    "\n",
    "Number of vertices= 4\n",
    "Number of faces= 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Constructing a Cube\n",
    "\n",
    "![SegmentLocal](results/360_cube.gif \"segment\")\n",
    "\n",
    "Number of vertices= 8\n",
    "Number of faces= 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Re-texturing a mesh\n",
    "\n",
    "![SegmentLocal](results/retexture.gif \"segment\")\n",
    "\n",
    "color1 = [0, 1, 0.5] - Teal\n",
    "\n",
    "color2 = [ 0, 0, 1] - Blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Camera Transformations\n",
    "\n",
    "![SegmentLocal](results/cow_trans_1_Q4.jpg \"segment\")\n",
    "\n",
    "\n",
    "R_relative & T_relative are as follows:\n",
    "\n",
    "Rotating 90 degrees about the z-axis anticlockwise, \n",
    "R_relative = [ [0, 1, 0],\n",
    "            [-1, 0, 0],\n",
    "            [0, 0, 1] ]\n",
    "\n",
    "No Translation therfore remains unchanged\n",
    "T_relative = [0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![SegmentLocal](results/cow_trans_2_Q4.jpg \"segment\")\n",
    "\n",
    "\n",
    "R_relative & T_relative are as follows:\n",
    "\n",
    "No rotation therfore remains Identity, \n",
    "R_relative = [ [1, 0, 0],\n",
    "            [0, 1, 0],\n",
    "            [0, 0, 1] ]\n",
    "\n",
    "Zooming out therefore translating along the positive z-axis\n",
    "T_relative = [0,0,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![SegmentLocal](results/cow_trans_3_Q4.jpg \"segment\")\n",
    "\n",
    "\n",
    "R_relative & T_relative are as follows:\n",
    "\n",
    "No rotation therfore remains Identity, \n",
    "R_relative = [ [1, 0, 0],\n",
    "            [0, 1, 0],\n",
    "            [0, 0, 1] ]\n",
    "\n",
    "Moving along the postive x-axis and negative y-axis by half a unit,\n",
    "T_relative = [0.5, -0.5, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![SegmentLocal](results/cow_trans_4_Q4.jpg \"segment\")\n",
    "\n",
    "\n",
    "R_relative & T_relative are as follows:\n",
    "\n",
    "Rotating 90 degrees anticlockwise about y-axis, \n",
    "R_relative = [ [0, 0, 1],\n",
    "            [0, 1, 0],\n",
    "            [-1, 0, 1] ]\n",
    "\n",
    "Moving along the negative x-axis and positive z-axis by 3 units,\n",
    "T_relative = [0.5, -0.5, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Rendering Generic 3D Representations\n",
    "### 5.1 Rendering Point Clouds from RGB-D Images\n",
    "\n",
    "![SegmentLocal](results/point_cloud_1.gif \"segment\")\n",
    "![SegmentLocal](results/point_cloud_2.gif \"segment\")\n",
    "![SegmentLocal](results/point_cloud_3.gif \"segment\")\n",
    "\n",
    "Moving from left to right the images are as follows:\n",
    "1. The point cloud corresponding to the first image\n",
    "2. The point cloud corresponding to the second image\n",
    "3. The point cloud formed by the union of the first 2 point clouds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Parametric Functions\n",
    "\n",
    "GIF of torus\n",
    "\n",
    "![SegmentLocal](results/torus.gif \"segment\")\n",
    "\n",
    "GIF of new object - catenoid\n",
    "\n",
    "![SegmentLocal](results/catenoid.gif \"segment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Implicit Surfaces\n",
    "\n",
    "GIF of torus-implict\n",
    "\n",
    "![SegmentLocal](results/torus_implicit.gif \"segment\")\n",
    "\n",
    "GIF of new object - gyroid\n",
    "\n",
    "![SegmentLocal](results/gyroid_implicit.gif \"segment\")\n",
    "\n",
    "\n",
    "Rendering as a mesh versus a point cloud involves several trade-offs across multiple factors such as rendering speed, quality, memory usage, and ease of use.\n",
    "\n",
    "Rendering Speed: Meshes are faster to render due to their structured representation, whereas, point clouds are slower since rendering unconnected points requires more memory bandwidth and processing.\n",
    "\n",
    "Rendering Quality: Meshes provide smooth, continuous surfaces ideal for high-quality visualizations, animations, and simulations. It is possible for point clouds to capture fine details but it still may appear disconnected or have gaps at lower resolutions.\n",
    "\n",
    "Memory Usage: Meshes generally require more memory than point clouds. However, they are more compact for visualization since fewer data points are needed to represent smooth surfaces. Point clouds are simpler in structure but can be highly memory-intensive. \n",
    "\n",
    "Ease of Use: Meshes are easier to manipulate in 3D modeling tools therfore widely used in graphics. However, generating accurate meshes from raw data (e.g., point clouds) can be computationally expensive. The vice-versa is true for point clouds because they are easier to generate directly from scanning technologies like LiDAR or photogrammetry. However, they possess an irregular structure which makes them harder to process and analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Do Something Fun\n",
    "Here's a cow sitting on a cube with an interesting zooming effect!\n",
    "\n",
    "![SegmentLocal](results/Q6.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sampling Points on Meshes\n",
    "\n",
    "![SegmentLocal](results/360_cow.gif \"segment\")![SegmentLocal](results/cow_10.gif \"segment\")\n",
    "\n",
    "![SegmentLocal](results/360_cow.gif \"segment\")![SegmentLocal](results/cow_100.gif \"segment\")\n",
    "\n",
    "![SegmentLocal](results/360_cow.gif \"segment\")![SegmentLocal](results/cow_1000.gif \"segment\")\n",
    "\n",
    "![SegmentLocal](results/360_cow.gif \"segment\")![SegmentLocal](results/cow_10000.gif \"segment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
